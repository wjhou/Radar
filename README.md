# <span style="font-variant:small-caps;">Radar</span>: Enhancing Radiology Report Generation with Supplementary Knowledge Injection

This repository is the implementation of [RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection](https://aclanthology.org/2024.findings-emnlp.528/). Before running the code, please install the prerequisite libraries, and follow our instructions to replicate the experiments.

## Overview

Large language models (LLMs) have demonstrated remarkable capabilities in various domains, including radiology report generation. Previous approaches have attempted to utilize multimodal LLMs for this task, enhancing their performance through the integration of domain-specific knowledge retrieval. However, these approaches often overlook the knowledge already embedded within the LLMs, leading to redundant information integration and inefficient utilization of learned representations. To address this limitation, we propose <span style="font-variant:small-caps;">Radar</span>, a framework for enhancing radiology report generation with supplementary knowledge injection. <span style="font-variant:small-caps;">Radar</span> improves report generation by systematically leveraging both the internal knowledge of an LLM and externally retrieved information. Specifically, it first extracts the model's inherent knowledge that aligns with expert image-based classification outputs. It then retrieves relevant supplementary knowledge to expand upon these insights. Finally, by aggregating both sources, <span style="font-variant:small-caps;">Radar</span> generates more accurate and informative radiology reports. Extensive experiments on MIMIC-CXR, <span style="font-variant:small-caps;">CheXpert Plus</span>, and <span style="font-variant:small-caps;">IU X-ray</span> demonstrate that our model outperforms state-of-the-art LLMs in both language quality and clinical accuracy
![Alt text](figure/framework.png?raw=true "Title")