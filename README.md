# <img src="figure/radar.png?raw=true" alt="Alt" height="38" style="vertical-align:middle;">  <span style="font-variant:small-caps;">RADAR</span>: Enhancing Radiology Report Generation with Supplementary Knowledge Injection

This repository is the implementation of [RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection](https://aclanthology.org/2024.findings-emnlp.528/). Before running the code, please install the prerequisite libraries, and follow our instructions to replicate the experiments.

## Overview

Large language models (LLMs) have demonstrated remarkable capabilities in various domains, including radiology report generation. Previous approaches have attempted to utilize multimodal LLMs for this task, enhancing their performance through the integration of domain-specific knowledge retrieval. However, these approaches often overlook the knowledge already embedded within the LLMs, leading to redundant information integration and inefficient utilization of learned representations. To address this limitation, we propose RADAR, a framework for enhancing radiology report generation with supplementary knowledge injection. RADAR improves report generation by systematically leveraging both the internal knowledge of an LLM and externally retrieved information. Specifically, it first extracts the model's inherent knowledge that aligns with expert image-based classification outputs. It then retrieves relevant supplementary knowledge to expand upon these insights. Finally, by aggregating both sources, RADAR generates more accurate and informative radiology reports. Extensive experiments on MIMIC-CXR, CheXpert Plus, and IU X-ray demonstrate that our model outperforms state-of-the-art LLMs in both language quality and clinical accuracy
![Alt text](figure/framework.png?raw=true "Title")